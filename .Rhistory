#install.packages("partykit")
#install.packages("CHAID", repos="http://R-Forge.R-project.org", type = "source")
#install.packages(c('rpart', 'rpart.plot'))
#install.packages('CHAID')
library('CHAID') # CHAID decision tree
library('rpart') # CART decision tree
library('rpart.plot') # plot decision trees
# load table
musch <- read.table(
file = "data/muschroom.csv",
sep = ",",
header = TRUE
)
# load table
musch <- read.table(
file = "C:/Users/Bouba/ENSAI Informatique/Apprentissage SupervisÃ©/TP2/data/muschroom.csv",
sep = ",",
header = TRUE
)
summary(musch)
# remove the X column
musch <- musch[, -1]
# train/test split
base <- musch[musch$echantillon == "base", ]
test <- musch[musch$echantillon == "test", ]
dim(base)
dim(test)
nrow(base)/nrow(musch) #Pourcentage de la base "Train"
nrow(test)/nrow(musch) #Pourcentage de la base "Test"
# Information on the rpart function
?rpart
?rpart.control
# define the parameters
parametres <- rpart.control(
minsplit = 60, # 60 observations minimum for a split to be considered
minbucket = 30, # a split should create node with at least 30 observations
xval = 100, # number of fold
maxcompete = 4, # number of competitor splits retained (equi reducteur)
maxsurrogate = 4, # number of surrogate splits to retain (equi divisant)
usesurrogate = 2, # how to deal with missing values
maxdepth = 30 # maximum depth of nodes regarding the root
)
# construct the model
model <- rpart(
formula = classe ~ .,
data = base,
method = "class",
control = parametres,
parms = list(split = 'gini')
)
# print the model
print(model)
# plot the tree
rpart.plot(model)
# print the results of the model
summary(model)
# evolution of the tree size and of the error based on the cp parameter
#Il s'agit de la repr?sentation de la l'erreur relative de validation crois?e
#selon la taille de l'arbre. Le 3e est s?lectionn? ici.
plotcp(model)
# probabilities for the two classes for each observations of the test set
predict(model, test)
# predicted class for each observtion
predtest <- predict(model, test, type = "class")
# confusion matrix
table(test$classe, predtest)
# error rate
error_rate <- sum(predtest != test$classe) / nrow(test)
error_rate
# build the model
model2 <- rpart(
classe ~ .,
data = base,
parms = list(
split = "gini",
loss = matrix(
c(0, 1, 1000, 0),
byrow = TRUE,
nrow = 2)
),
control = parametres
)
# print the model
print(model2)
# plot the tree
rpart.plot(model2)
# print the results of the model
summary(model2)
# evolution of the tree size and of the error based on the cp parameter
plotcp(model2)
# probabilities for the two classes for each observations of the test set
predict(model2,test)
# predicted class for each observtion
predtest2 <- predict(model2, test, type = "class")
# confusion matrix
table(test$classe, predtest2)
# calcul du taux d'erreur en test
sum(predtest2!= test$classe)/nrow(test)
# see the help page
?chaid
# chaid decision tree
model3 <- chaid(
formula = classe ~ .,
data = base,
control = chaid_control(
minsplit = 60,
minbucket = 30
)
)
# model results
print(model3)
# plot the model
plot(
model3,
uniform = TRUE,
compress = TRUE,
margin = 0.2,
branch = 0.3
)
